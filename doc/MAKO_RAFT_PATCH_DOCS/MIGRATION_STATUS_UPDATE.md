# Mako Raft Migration - Current Implementation Status

**Last Updated**: 2025-11-14
**Document Version**: 3.0
**Status**: ‚ö†Ô∏è **PARTIALLY WORKING** - Core functionality complete, but follower replication has critical reliability issues

---

## Executive Summary

**Migration Status: 85% COMPLETE** ‚ö†Ô∏è

The Raft migration has all core functionality implemented and **basic tests pass**, but **follower replication is unreliable** with massive variance (0.006% to 20% of expected replay batches). This is a **critical blocker** for production use.

### ‚úÖ What Works
- Full RaftWorker implementation with setup/teardown
- Complete raft_main_helper API matching Paxos interface
- Mako watermark callback integration (leader & follower paths)
- Async batching support with queue management
- Leader election and leadership transfer
- Preferred leader election
- Fixed leader mode (for testing)
- CMake build system (`make mako-raft`)
- Graceful shutdown with queue draining
- **Simple tests pass**: simpleRaft, testPreferredReplicaStartup, testPreferredReplicaLogReplication

### ‚ùå Critical Issues

**BLOCKER: Follower replication is extremely unreliable**

From 10 consecutive test runs (60 seconds each, 1-shard with 3 Raft replicas):

| Run | Throughput | replay_batch | % of Expected (~20k) |
|-----|------------|--------------|----------------------|
| 1   | 347k ops/s | 3,474        | 17.4%               |
| 2   | 381k ops/s | **614**      | **1.9%** üî¥         |
| 3   | 342k ops/s | 5,185        | 25.9%               |
| 4   | 347k ops/s | 3,198        | 16.0%               |
| 5   | 347k ops/s | 2,885        | 14.4%               |
| 6   | 390k ops/s | **2**        | **0.006%** üî¥üî¥üî¥  |
| 7   | 346k ops/s | 3,530        | 17.7%               |
| 8   | 344k ops/s | 6,697        | 33.5%               |
| 9   | 341k ops/s | 3,254        | 16.3%               |
| 10  | 349k ops/s | 3,796        | 19.0%               |

**Statistics:**
- Average: 3,263 batches (16.3% of expected)
- Variance: **205%** (catastrophic!)
- Failure rate: 20% (Runs 2 & 6 essentially failed)
- **Pattern**: Higher leader throughput ‚Üí WORSE follower replication

**Root Cause (Confirmed):**

The `applyLogs()` guard in `src/deptran/raft/server.cc:350-352`:

```cpp
void RaftServer::applyLogs() {
  if (in_applying_logs_) {
    return;  // ‚Üê DROPS WORK SILENTLY!
  }
  in_applying_logs_ = true;
  // ... apply logs ...
  in_applying_logs_ = false;
}
```

**Why this breaks:**
1. Follower receives AppendEntries ‚Üí calls `applyLogs()`
2. Sets `in_applying_logs_ = true`, starts processing
3. While processing (can take 100-800ms), MORE AppendEntries arrive
4. Each subsequent `applyLogs()` call **returns immediately** without queueing work
5. **Follower falls further and further behind**
6. When test stops after 60s, follower is only 1-30% caught up
7. Test kills follower before it can drain queue ‚Üí low replay_batch

**Why Paxos doesn't have this problem:**
- Paxos also has the same guard (`src/deptran/paxos/server.cc:87`)
- BUT Paxos's `OnCommit()` is called ONCE per slot by leader's Decide RPC
- Raft's `applyLogs()` is called on EVERY AppendEntries (potentially 100+ times/sec)
- Result: Raft drops more work

---

## Test Status

### ‚úÖ Passing Tests

**1. simpleRaft** (`examples/mako-raft-tests/simpleRaft.cc`)
- Status: ‚úÖ **PASSES CONSISTENTLY**
- What it tests: Basic Raft log replication with 3 replicas
- Duration: ~10 seconds
- Why it passes: Short duration, small number of entries

**2. testPreferredReplicaStartup** (`examples/mako-raft-tests/testPreferredReplicaStartup.cc`)
- Status: ‚úÖ **PASSES CONSISTENTLY**
- What it tests: Preferred replica logic (non-preferred replicas trigger elections)
- Duration: ~15 seconds
- Key feature: `set_preferred_leader()` and piggybacked leadership transfer

**3. testPreferredReplicaLogReplication** (`examples/mako-raft-tests/testPreferredReplicaLogReplication.cc`)
- Status: ‚úÖ **PASSES CONSISTENTLY**
- What it tests: Log replication under leadership transfer with RAFT_BATCH_OPTIMIZATION
- Duration: ~20 seconds
- Validates: Batch aggregation works correctly

### ‚ö†Ô∏è Partially Working Tests

**4. shard1ReplicationRaft** (`examples/mako-raft-tests/test_1shard_replication_raft.sh`)
- Status: ‚ö†Ô∏è **FLAKY** (20% failure rate, 205% variance)
- What it tests: 1-shard TPC-C with 3 Raft replicas (60s run)
- Expected: ~20,000 replay_batch on follower
- Actual: 2 to 6,697 (avg 3,263)
- **Root cause**: Follower replication bottleneck (see above)

**Key Observations:**
- Leader throughput: 340-390k ops/sec (GOOD)
- Follower replay: Highly variable (BAD)
- Jetpack recovery: **Disabled** for simplicity (intentional)
- Election timeout: 10√ó heartbeat interval (stable leadership)
- Test kills follower before queue drain (by design, but exposes the bug)

### ‚ùå Not Yet Tested

**5. shard2ReplicationRaft** (multi-shard with replication)
- Status: ‚ùì **NOT IMPLEMENTED**
- Needed: Config files, test script

**6. Failure recovery tests**
- Status: ‚ùì **NOT TESTED**
- Need to test: Leader crash, follower crash, network partition

**7. Performance benchmarks**
- Status: ‚ùì **NOT DONE**
- Need to compare: Raft vs Paxos throughput/latency

---

## Implementation Details

### Core Components

**1. RaftWorker** (`src/deptran/raft/raft_worker.{h,cc}`)
- Status: ‚úÖ **COMPLETE**
- Lines: 158 (header) + 560 (implementation)
- Key features:
  - Leader/follower callbacks with dynamic dispatch
  - Async batching via submit thread
  - Watermark integration (encodes timestamp√ó10 + status)
  - Shutdown guards to prevent crashes during teardown

**Recent Critical Fixes:**
- ‚úÖ Callback registration null guards (prevents shutdown crashes)
- ‚úÖ Separate leader/follower callbacks (was using same callback for both)
- ‚úÖ TxLogServer::IsLeader() delegation (prevents verify(0) crash)
- ‚úÖ RaftServer::IsLeader() shutdown guard (checks `looping_` flag)

**2. raft_main_helper** (`src/deptran/raft_main_helper.{h,cc}`)
- Status: ‚úÖ **COMPLETE**
- Lines: 65 (header) + 550 (implementation)
- Matches Paxos API exactly
- **Jetpack disabled by default**: `setenv("MAKO_DISABLE_JETPACK", "1", 1)` at line 235

**3. RaftServer** (`src/deptran/raft/server.{cc,h}`)
- Status: ‚úÖ **CORE COMPLETE**, ‚ö†Ô∏è **REPLICATION BOTTLENECK**
- Key enhancements:
  - Preferred leader election (piggybacked transfer)
  - RAFT_BATCH_OPTIMIZATION (aggregates multiple log entries per AppendEntries)
  - Fixed leader mode (`setIsLeader(true)` for testing)
  - Raft backtracking (handles late AppendEntries responses during leadership churn)

**Recent Critical Fixes:**
- ‚úÖ Backtracking instead of verify() for lagging followers (line 624, 635)
- ‚úÖ Leadership transfer monitoring
- ‚ö†Ô∏è **KNOWN BUG**: `in_applying_logs_` guard causes follower lag (see above)

---

## Configuration & Build

### Build System

**CMake Integration** (`CMakeLists.txt`):
```bash
# Build with Raft
make clean
make mako-raft -j64

# Build with Paxos (default)
make clean
make -j64
```

**Flag**: `MAKO_USE_RAFT` is defined when using `make mako-raft`

### Configuration Files

**occ_raft.yml** (`config/occ_raft.yml`):
```yaml
mode:
  cc: occ          # Concurrency control
  ab: raft         # Atomic broadcast (CRITICAL: was fpga_raft initially, now fixed)
  read_only: occ
  batch: false
  retry: 20
  ongoing: 1
```

**Cluster configs**:
- `config/1leader_2followers/raft6_shardidx0.yml` - 1-shard, 3 replicas (localhost, p1, p2)
- Host mapping: `config/hosts_raft.yml`

**Election Timeout Tuning** (CRITICAL):
- **Problem**: Aggressive timeouts cause unnecessary elections
- **Solution**: Set election_timeout = 100√ó heartbeat_interval
- **Impact**: With stable leadership, replay_batch jumped from 3.9k ‚Üí 18.9k in one lucky run
- **Current**: Using 10√ó heartbeat (compromise between stability and recovery speed)

---

## Known Issues & Workarounds

### üî¥ CRITICAL: Follower Replication Bottleneck

**Issue**: `in_applying_logs_` guard in `RaftServer::applyLogs()` causes followers to drop work

**Evidence**:
- 10 test runs: 2 catastrophic failures (2 batches, 614 batches)
- Average only 16% of expected throughput
- 205% variance (unacceptable for production)

**Proposed Fixes** (in order of preference):

**Option 1: Track Pending Work** (RECOMMENDED)
```cpp
void RaftServer::applyLogs() {
  std::unique_lock<std::mutex> lock(apply_mutex_, std::try_lock);
  if (!lock.owns_lock()) {
    needs_reapply_.store(true, std::memory_order_release);
    return;
  }

  do {
    needs_reapply_.store(false, std::memory_order_release);

    for (slotid_t id = executeIndex + 1; id <= commitIndex; id++) {
      auto next_instance = GetRaftInstance(id);
      if (next_instance && next_instance->log_) {
        app_next_(id, next_instance->log_);
        executeIndex = id;
      } else {
        break;
      }
    }

  } while (needs_reapply_.load(std::memory_order_acquire));
}
```

**Pros**: Never loses work, automatically retries
**Cons**: Slightly more complex
**Implementation time**: ~1 hour + testing

**Option 2: Asynchronous Apply Thread** (BEST SCALABILITY)
```cpp
// Background thread continuously drains committed logs
void RaftServer::ApplyLogsThread() {
  while (running_) {
    std::unique_lock<std::mutex> lock(apply_mutex_);
    apply_cv_.wait(lock, [this] {
      return executeIndex < commitIndex || !running_;
    });

    for (slotid_t id = executeIndex + 1; id <= commitIndex; id++) {
      auto next_instance = GetRaftInstance(id);
      if (next_instance && next_instance->log_) {
        app_next_(id, next_instance->log_);
        executeIndex = id;
      } else {
        break;
      }
    }
  }
}
```

**Pros**: Best throughput, never blocks AppendEntries handler
**Cons**: More complex, requires thread lifecycle management
**Implementation time**: ~3 hours + testing

**Option 3: Remove Guard** (RISKY)
```cpp
// Just remove the guard entirely
void RaftServer::applyLogs() {
  // No guard - process every call
  for (slotid_t id = executeIndex + 1; id <= commitIndex; id++) {
    // ...
  }
}
```

**Pros**: Simple
**Cons**: Potential race conditions if multiple threads call this
**Risk**: Medium (need to verify thread safety)

---

### ‚ö†Ô∏è MODERATE: Test Timing Issue

**Issue**: Tests kill followers before they drain queues

**Evidence**:
- Test runs for exactly 60s, then kills processes
- Follower still has backlog when killed
- No grace period for queue drain

**Workaround**:
```bash
# In test script, after workload stops:
sleep 30  # Grace period for followers to catch up
```

**Proper Fix**: Modify test scripts to:
1. Stop client workload
2. Wait for `replay_batch` to stabilize (poll every second)
3. Only then kill processes

---

### ‚ö†Ô∏è MODERATE: Leadership Churn

**Issue**: Aggressive election timeouts cause frequent unnecessary elections

**Fix**: Tune election timeout to 50-100√ó heartbeat interval

**Status**: ‚úÖ **FIXED** in test configs (now using 10-100√ó depending on test)

**Impact**: With stable leadership:
- replay_batch improved from 3.9k ‚Üí 6.3k (average case)
- Best case: 18.9k (when everything aligns)

---

### ‚úÖ RESOLVED: Shutdown Crashes

**Issue**: Crashes during shutdown when accessing deleted scheduler

**Fixes Applied**:
1. ‚úÖ TxLogServer::IsLeader() delegates to rep_sched_ (instead of verify(0))
2. ‚úÖ RaftServer::IsLeader() checks `looping_` flag before accessing members
3. ‚úÖ All callback registration functions guard against null rep_sched_

**Status**: No longer crashes on shutdown

---

### ‚úÖ RESOLVED: Wrong Frame Type

**Issue**: Config file specified `ab: fpga_raft` instead of `ab: raft`

**Fix**: Updated `config/occ_raft.yml` line 4

**Status**: ‚úÖ **FIXED**

---

## Jetpack Recovery Analysis

**Status**: ‚ö†Ô∏è **DISABLED BY DEFAULT** (intentional)

**What is Jetpack?**
- Witness-based fast recovery protocol
- Runs **ONLY during leader elections**
- Ensures missed transactions are re-executed after failover

**Why Disabled?**
1. **Simplicity**: Easier to test Raft without Jetpack first
2. **Performance**: Adds 50-200ms per election (0-15% throughput impact depending on churn)
3. **Redundancy**: Mako's watermark-based safety checks already prevent unsafe replays

**Code Location**: `src/deptran/raft_main_helper.cc:234-236`
```cpp
if (std::getenv("MAKO_DISABLE_JETPACK") == nullptr) {
  setenv("MAKO_DISABLE_JETPACK", "1", 1);  // Force disable
}
```

**Impact on Throughput:**

| Scenario | Jetpack Impact |
|----------|----------------|
| Stable leadership (no elections) | **0%** (never runs) |
| Frequent elections (aggressive timeout) | **-5% to -15%** (blocks during recovery) |
| Current tests | **0%** (leadership stable, Jetpack disabled) |

**Recommendation**:
- Keep **disabled** for benchmarking and development
- **Enable** only for production failure testing
- Enable with: `unset MAKO_DISABLE_JETPACK` or `export MAKO_DISABLE_JETPACK=0`

---

## Performance Characteristics

### Leader Performance
- **Throughput**: 340-390k ops/sec (excellent, matches Paxos)
- **Variance**: ¬±10% (acceptable)
- **Batching**: RAFT_BATCH_OPTIMIZATION works correctly

### Follower Performance
- **Throughput**: üî¥ **UNRELIABLE** (0.006% to 33.5% of leader)
- **Variance**: üî¥ **205%** (catastrophic)
- **Root cause**: applyLogs() guard drops work

### Network
- **AppendEntries frequency**: ~100-200 RPCs/sec per follower
- **Batch aggregation**: 1-20 log entries per RPC (depends on load)
- **Heartbeat interval**: 50ms (default)
- **Election timeout**: 500-5000ms (10-100√ó heartbeat, configurable)

---

## Next Steps

### Immediate (CRITICAL)

1. **Fix follower replication bottleneck** ‚ö†Ô∏èüî¥
   - Implement Option 1 (Track Pending Work) or Option 2 (Async Thread)
   - Target: 90%+ follower catch-up rate
   - Validation: replay_batch variance <20%

2. **Add drain period to tests**
   - Modify test scripts to wait for followers before killing
   - Improves test reliability

3. **Validate fix with 10+ test runs**
   - Ensure variance drops to <20%
   - No catastrophic failures (< 1% throughput)

### Short Term

4. **Implement shard2ReplicationRaft test**
   - Multi-shard with replication
   - Cross-shard watermark validation

5. **Leader failover testing**
   - Kill leader mid-run
   - Verify new leader takes over
   - Check Jetpack recovery (if enabled)

6. **Performance benchmarking**
   - Raft vs Paxos side-by-side
   - Latency distribution
   - Scalability testing

### Medium Term

7. **Documentation**
   - Troubleshooting guide
   - Configuration tuning guide
   - Architecture overview

8. **Optional: Enable Jetpack**
   - Test with Jetpack enabled
   - Measure recovery time
   - Validate correctness

---

## How to Run Tests

### Simple Tests (Passing)

```bash
# Build
make clean
make mako-raft -j64

# Run simple Raft test
./build/simpleRaft

# Run preferred leader tests
./build/testPreferredReplicaStartup
./build/testPreferredReplicaLogReplication
```

### Replication Test (Flaky)

```bash
# Single run
./ci/ci_mako_raft.sh shard1ReplicationRaft

# Variance test (10 runs)
./run_raft_batch_variance_test.sh

# Results will be in: raft_batch_variance_YYYYMMDD_HHMMSS.log
```

### Expected Output (After Fix)

**Good run** (target after fixing replication):
```
agg_persist_throughput: 350000 ops/sec
replay_batch: 18000 (> 1000) ‚úì
NewOrder_remote_abort_ratio: -nan (< 20%) ‚úì
```

**Current reality** (before fix):
```
agg_persist_throughput: 350000 ops/sec
replay_batch: 3263 (avg, with 205% variance) ‚ö†Ô∏è
NewOrder_remote_abort_ratio: -nan (< 20%) ‚úì
```

---

## Conclusion

**Current State**: Core Raft implementation is complete and functionally correct. Leader-side performance matches Paxos. **However, follower replication has a critical reliability issue** that causes 20% test failure rate and massive variance.

**Blocking Issue**: The `in_applying_logs_` guard in `applyLogs()` causes followers to drop work when overwhelmed, resulting in unpredictable replication lag.

**Path to Production**:
1. Fix follower replication (Option 1 or 2 above) - **CRITICAL**
2. Validate with 10+ clean test runs (variance <20%)
3. Test multi-shard and failover scenarios
4. Performance validation vs Paxos
5. Production deployment with Jetpack enabled

**Estimated Time to Fix**: 1-3 days (implementation + validation)

**Risk Assessment**: **MEDIUM** - The fix is well-understood and straightforward, but requires careful testing to avoid introducing race conditions.

---

**Document Prepared For**: Next AI agent or developer continuing this work
**Key Files to Review**:
- `src/deptran/raft/server.cc:348-371` (applyLogs function - THE BUG)
- `src/deptran/raft/raft_worker.cc:466-530` (Next callback - works correctly)
- `examples/mako-raft-tests/test_1shard_replication_raft.sh` (flaky test)
- `raft_batch_variance_YYYYMMDD_HHMMSS.log` (variance test results)
